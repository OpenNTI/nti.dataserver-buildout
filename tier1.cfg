[buildout]
extends = 
		haproxy_nginx_stunnel.cfg

parts +=
	  haproxy
	  stunnel

#[stunnel-conf]
#recipe = z3c.recipe.filetemplate
#source-directory = templates
#dest-directory = ${deployment:root-directory}
#force-overwrite = true
#files = stunnel.conf

#[stunnel-cert]
# For creating the stunnel cert.
# In this case, we simply copy a default,
# but for production uses, use openssl.
# This should come *before* stunnel itself is built
# to avoid interactive prompts
#recipe = collective.recipe.cmd
#on_install = true
#cmds = cp ${buildout:directory}/certs/stunnel_default.pem ${environment:stunnel_cert_file}

[haproxy-conf]
recipe = z3c.recipe.filetemplate
source-directory = templates
dest-directory = ${deployment:root-directory}
# the main conf file is already installed
# as part of building nginx, we must overwrite it
force-overwrite = true
files = haproxy-tier1.cfg haproxy-tier1-priviledged.cfg

# The trailing comment matters; see developer_zeo_conf
haproxy_backend_port_rewrite = #

# Max Haproxy connections (depends on ulimit)
haproxy_maxconn = 60000

# If we have additional incoming hosts that
# define SSL traffic, such as a front-end proxy,
# list them here. Each line is of the form
# acl is_ssl RULE. Be careful with this.
# To match all incoming traffic, assuming that
# ssl is always the case, you can use something like this:
#       acl is_ssl so_id ${environment:haproxy_http_port}
haproxy_addl_ssl_acls =

# We need to define our host to environment mappings
haproxy_hostname_backend_map =

# Define the destination port for each backend
haproxy_app_backend1_port = 20006
haproxy_app_backend2_port = 20016
haproxy_app_backend3_port = 20026
haproxy_app_backend4_port = 20036
haproxy_app_backend5_port = 20046
haproxy_app_backend6_port = 20056

# Define the servers for each backend
haproxy_app_backend1 =
	server app100 10.50.0.100:${:haproxy_app_backend1_port} weight 1 on-error mark-down check inter 2000 rise 2 fall 2 observe layer7 send-proxy
	server app101 10.50.0.101:${:haproxy_app_backend1_port} weight 1 on-error mark-down check inter 2000 rise 2 fall 2 observe layer7 send-proxy
	server app102 10.50.8.102:${:haproxy_app_backend1_port} weight 1 on-error mark-down check inter 2000 rise 2 fall 2 observe layer7 send-proxy
	server app103 10.50.8.103:${:haproxy_app_backend1_port} weight 1 on-error mark-down check inter 2000 rise 2 fall 2 observe layer7 send-proxy

haproxy_app_backend2 =
	server app50 10.50.0.50:${:haproxy_app_backend2_port} weight 1 on-error mark-down check inter 2000 rise 2 fall 2 observe layer7 send-proxy

haproxy_app_backend3 =
	server app100 10.50.0.100:${:haproxy_app_backend3_port} weight 1 on-error mark-down check inter 2000 rise 2 fall 2 observe layer7 send-proxy
	server app101 10.50.0.101:${:haproxy_app_backend3_port} weight 1 on-error mark-down check inter 2000 rise 2 fall 2 observe layer7 send-proxy
	server app102 10.50.8.102:${:haproxy_app_backend3_port} weight 1 on-error mark-down check inter 2000 rise 2 fall 2 observe layer7 send-proxy
	server app103 10.50.8.103:${:haproxy_app_backend3_port} weight 1 on-error mark-down check inter 2000 rise 2 fall 2 observe layer7 send-proxy

haproxy_app_backend4 =
	server app50 10.50.0.50:${:haproxy_app_backend4_port} weight 1 on-error mark-down check inter 2000 rise 2 fall 2 observe layer7 send-proxy

haproxy_app_backend5 =
	server app50 10.50.0.50:${:haproxy_app_backend5_port} weight 1 on-error mark-down check inter 2000 rise 2 fall 2 observe layer7 send-proxy

haproxy_app_backend6 =
	server app50 10.50.0.50:${:haproxy_app_backend6_port} weight 1 on-error mark-down check inter 2000 rise 2 fall 2 observe layer7 send-proxy

# Set this to 'accept-proxy' if a frontend will
# also be haproxy; then it should use send-proxy in its
# server line and this will obviate the need for server-close
# to get x-forwarded-for
haproxy_http_accept_proxy =

# HAproxy stats on a unix socket. See
# http://cbonte.github.io/haproxy-dconv/configuration-1.5.html#9.2
haproxy_stats_socket = ${deployment:run-directory}/haproxy.sock
# TODO: There are recipes that enumerate other sections; we
# probably want to use those here to avoid having to
# manually list out all server ips again. Alternatively,
# our own meta recipe.

