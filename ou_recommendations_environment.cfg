[buildout]
extends =
		versions.cfg
		spark.cfg
		orgsync.cfg
		tableau.cfg
		deployment.cfg
		mathplacement.cfg
		ou_recommendations.cfg

update-versions-file = versions.cfg
show-picked-versions = true

parts =
		pip
		cython
		pyspark
		scipy
		scikit_learn
		eggs
		passwords
		checkversions
		tableau-conf
		spark-hive-conf
		orgsync-key-conf
		orgsync-db-conf
		ourecomm-db-conf
		clean-pyc

extensions = mr.developer

mr.developer-threads = 7
sources-dir = sources
auto-checkout = *
always-checkout = true

[orgsync-sources]
<= orgsync-BASE-sources

[sources]
z3c.recipe.filetemplate = git git@github.com:NextThought/z3c.recipe.filetemplate.git
<= spark-sources
   orgsync-sources
   tableau-sources
   mathplacement-BASE-sources
   ou-recommendations-SPARK-sources

[cython]
recipe = zc.recipe.egg
eggs = cython

[pip]
recipe = zc.recipe.egg
eggs = pip
	
[pyspark]
recipe = zc.recipe.egg
eggs =
	 numpy
	 pandas
	 pyspark

[scipy]
recipe = zc.recipe.egg
eggs =
   	 scipy

[scikit_learn]
recipe = zc.recipe.egg
eggs =
   	 scikit-learn

[xgboost]
recipe = zc.recipe.egg
eggs =
 	 xgboost
		 
[eggs]
recipe = zc.recipe.egg
eggs =
	 cython
	 pip
	 PyMySQL
	 pyspark
	 nti.nose_traceback_info
	 ${spark-ALL-eggs:eggs}
	 ${tableau-ALL-eggs:eggs}
	 ${orgsync-BASE-eggs:eggs}
	 ${mathplacement-BASE-eggs:eggs}
	 ${ou-recommendations-SPARK-eggs:eggs}

interpreter = python
dependent-scripts = true
# Make sure all these scripts know where their
# home is, and that it is a buildout
initialization =
	import os
	os.environ['DATASERVER_DIR_IS_BUILDOUT'] = "1"
	os.environ['DATASERVER_DIR'] = "${deployment:root-directory}"
	os.environ['DATASERVER_ETC_DIR'] = "${deployment:etc-directory}"

[checkversions]
recipe = zc.recipe.egg
eggs = z3c.checkversions [buildout]

[passwords]
recipe = nti.recipes.passwords
file = ourecomm.pass.cast5

[clean-pyc]
recipe = collective.recipe.cmd
on_install = true
on_update = true
cmds = find ${buildout:sources-dir} -name "*.py[cod]" -delete

[orgsync]
access-key = ${passwords:orgsync_key}

[orgsync-key-conf]
recipe = z3c.recipe.filetemplate
source-directory = templates
dest-directory = ${deployment:root-directory}
files = 795-orgsync-key.zcml

[orgsync-db]
dbname = orgsync
user = ntiuser
twophase = True
autocommit = False
driver = mysql+pymysql
host = localhost
password = ${passwords:sql_users_passwd}

[orgsync-db-conf]
recipe = z3c.recipe.filetemplate
source-directory = templates
dest-directory = ${deployment:root-directory}
files = 790-orgsync-db.zcml

[ourecomm-db]
dbname = ourecomm
user = ourecomm
twophase = True
autocommit = False
driver = mysql+pymysql
host = localhost
password = ${passwords:sql_users_passwd}

[ourecomm-db-conf]
recipe = z3c.recipe.filetemplate
source-directory = templates
dest-directory = ${deployment:root-directory}
files = 790-ourecomm-db.zcml

[spark-hive]
master = spark://ip-172-31-30-254.ec2.internal:7077
log-level = ERROR
location = /home/ec2-user/dtap-warehouse
app-name = OU-Recommendations

[spark-hive-conf]
recipe = z3c.recipe.filetemplate
source-directory = templates
dest-directory = ${deployment:root-directory}
files = 800-spark-hive.zcml

[tableau]
url = https://tableau.ou.edu
site = gjh
username = higg2108
password = ${passwords:tableau_passwd}

[tableau-conf]
recipe = z3c.recipe.filetemplate
source-directory = templates
dest-directory = ${deployment:root-directory}
files = 900-tableau.zcml
